{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "from datetime import datetime,date\n",
    "from numpy import nan as Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Loop Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring our URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_earth_mostfunded = 'https://www.kickstarter.com/discover/advanced?category_id=16&sort=most_funded&seed=2567796&page=1'\n",
    "apps_earth_mostfunded = 'https://www.kickstarter.com/discover/advanced?category_id=332&sort=most_funded&seed=2567796&page=1'\n",
    "software_earth_mostfunded = 'https://www.kickstarter.com/discover/advanced?category_id=51&sort=most_funded&seed=2567796&page=1'\n",
    "web_earth_mostfunded = 'https://www.kickstarter.com/discover/advanced?category_id=342&sort=most_funded&seed=2567796&page=1'\n",
    "\n",
    "urls = [apps_earth_mostfunded,software_earth_mostfunded,web_earth_mostfunded]\n",
    "url = apps_earth_mostfunded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_kickstarter_project(url_project):\n",
    "    \n",
    "    # Stage HTML soup for scraping\n",
    "    headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "    response = get(url_project, headers=headers)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Project\n",
    "    try: \n",
    "        #closed\n",
    "        project = html_soup.find('a', class_='hero__link').text\n",
    "        #live = False\n",
    "    except: \n",
    "        try:\n",
    "            project = re.findall(r'medium mb3\">(.*?)</h2>',str(html_soup))[0]\n",
    "        except:\n",
    "            project = None\n",
    "\n",
    "    # Backers\n",
    "    try:\n",
    "        backers = html_soup.find('div',class_='NS_campaigns__spotlight_stats').b.text\n",
    "        backers = re.sub(' backers','',backers)\n",
    "        backers = int(re.sub(',','',backers))\n",
    "    except:\n",
    "        try:\n",
    "            backers = re.findall(r'type-24-md medium soft-black\"><span>(.*?)</span>',str(html_soup))[0]\n",
    "        except:\n",
    "            backers = None\n",
    "\n",
    "    # Pledged\n",
    "    try:\n",
    "        pledged = html_soup.find('h3', class_='mb0')\n",
    "        pledged = re.sub(',','',pledged.span.text)\n",
    "        #pledged = re.sub('$','',pledged)\n",
    "        pledged_num = sum(c.isalpha() for c in pledged)\n",
    "        pledged = int(pledged[pledged_num+1:])\n",
    "    except:\n",
    "        try:\n",
    "            pledged = re.findall(r'class=\"soft-black\">(.*?)</span>',str(html_soup))[0]\n",
    "            pledged_num = sum(c.isalpha() for c in pledged)\n",
    "            pledged = int(pledged[pledged_num+1:])\n",
    "        except:\n",
    "            pledged = None\n",
    "\n",
    "    # Goal\n",
    "    try:\n",
    "        goal = html_soup.find('div', class_='type-12').span.text\n",
    "        goal = re.sub(',','',goal)\n",
    "        #goal = re.sub('$','',goal)\n",
    "        goal_num = sum(c.isalpha() for c in goal)\n",
    "        goal = int(goal[goal_num+1:])\n",
    "    except:\n",
    "        try:\n",
    "            goal = re.findall(r'class=\"money\">(.*?)</span>',str(html_soup))[0]\n",
    "            goal = re.sub(',','',goal)\n",
    "            #goal = re.sub('$','',goal)\n",
    "            goal_num = sum(c.isalpha() for c in goal)\n",
    "            goal = int(goal[goal_num+1:])\n",
    "        except:\n",
    "            goal = None\n",
    "    \n",
    "    # Pct funded\n",
    "    try:\n",
    "        pct_funded = float(pledged/goal)\n",
    "    except:\n",
    "        pct_funded = None\n",
    "    \n",
    "    # Succesful\n",
    "    try:\n",
    "        successful = True if pct_funded >= 1 else False\n",
    "    except:\n",
    "        successful = None\n",
    "    \n",
    "    # Funding period\n",
    "    try:\n",
    "        times = html_soup.find('p', class_='f5').contents\n",
    "        funding_start_dt = times[1].text\n",
    "        funding_end_dt = times[3].text\n",
    "        funding_start_dt = datetime.strptime(funding_start_dt, '%b %d, %Y')\n",
    "        funding_end_dt = datetime.strptime(funding_end_dt, '%b %d, %Y')\n",
    "    except:\n",
    "        funding_start_dt,funding_end_dt = None,None\n",
    "    \n",
    "    # Live\n",
    "    try:\n",
    "        live = True if funding_end_dt > datetime.now() else False\n",
    "    except:\n",
    "        live = True\n",
    "    \n",
    "    # Location\n",
    "    try:\n",
    "        if len(html_soup.find_all('a', class_='grey-dark')) == 3:\n",
    "            location = html_soup.find_all('a', class_='grey-dark')[1].text.strip()\n",
    "        else:\n",
    "            location = html_soup.find_all('a', class_='grey-dark')[0].text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            location = re.findall(r'class=\"ml1\">(.*?)</span>',str(html_soup))[1]\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "    # Category\n",
    "    try:\n",
    "        if len(html_soup.find_all('a', class_='grey-dark')) == 3:\n",
    "            category = html_soup.find_all('a', class_='grey-dark')[2].text.strip()\n",
    "        else:\n",
    "            category = html_soup.find_all('a', class_='grey-dark')[1].text.strip()\n",
    "    except:\n",
    "        try:\n",
    "            category = re.findall(r'class=\"ml1\"><span>(.*?)</span>',str(html_soup))[0]\n",
    "        except:\n",
    "            category = None\n",
    "\n",
    "    # Tags\n",
    "    try:\n",
    "        if len(html_soup.find_all('a', class_='grey-dark')) == 3:\n",
    "            tag = html_soup.find_all('a', class_='grey-dark')[0].text.strip()\n",
    "        else:\n",
    "            tag = None\n",
    "    except:\n",
    "        tag = None\n",
    "\n",
    "    # Summary\n",
    "    try:\n",
    "        summary = html_soup.find('span', class_='content').text.strip()\n",
    "    except:\n",
    "        summary = None\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        description_ = html_soup.find('div', class_='full-description')\n",
    "        description = ''\n",
    "        for string in description_.stripped_strings:\n",
    "            description += string\n",
    "    except:\n",
    "        description = None\n",
    "\n",
    "    scrape = [project,backers,pledged,goal,pct_funded,successful,funding_start_dt,\n",
    "              funding_end_dt,live,location,category,tag,summary,description]\n",
    "\n",
    "    return scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web browsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def browse_kickstarter_results(urls):\n",
    "    \n",
    "    # Create empty DataFrame that will contain results of our scraping\n",
    "    head = ['project','backers','pledged','goal','pct_funded','successful','funding_start_dt',\n",
    "            'funding_end_dt','live','location','category','tag','summary','description','url']\n",
    "    scrape_df = pd.DataFrame(columns=head)\n",
    "\n",
    "    # Loop through each URL\n",
    "    for url in urls:\n",
    "\n",
    "        # Stage HTML soup for scraping Projects page\n",
    "        headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "        response = get(url, headers=headers) \n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Store results count\n",
    "        results_count = html_soup.find('b', class_='count')\n",
    "        results_count = results_count.text.strip()\n",
    "        results_count = re.sub(' projects','',results_count)\n",
    "        results_count = re.sub(',','',results_count)\n",
    "        results_count = int(results_count)\n",
    "\n",
    "        # Store loop iteration count to determine how many times to execute subsequent loop\n",
    "        load_iter = int(results_count/12)\n",
    "        load_iter = load_iter+1\n",
    "\n",
    "        # Loop through results and scrape\n",
    "        for i in log_progress(range(1,load_iter)):\n",
    "\n",
    "            # Update URL with page count\n",
    "            url_ = url[:-1]+str(i)\n",
    "            \n",
    "            # Open and close browser to keep jupyter from timing out\n",
    "            browser = webdriver.Firefox()\n",
    "            browser.get(url_)\n",
    "            sleep(randint(1,2))\n",
    "            browser.quit()\n",
    "\n",
    "            # Stage HTML soup for scraping Projects page\n",
    "            headers_ = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "            response_ = get(url_, headers=headers_) \n",
    "            html_soup_ = BeautifulSoup(response_.text, 'html.parser')\n",
    "\n",
    "            # Find projects' relevant HTML tags\n",
    "            container = html_soup_.find_all(lambda tag: tag if tag.has_attr('data-pid') else None)\n",
    "\n",
    "            # Loop through each page's 12 results \n",
    "            for i in range(len(container)):\n",
    "\n",
    "                # Extract URL for each result\n",
    "                s = str(container[i])\n",
    "                try:\n",
    "                    regex = re.search(r'https://www.kickstarter.com/projects/(.*?)&quot',s).group(1)\n",
    "                except:\n",
    "                    regex = re.search(r'https://www.kickstarter.com/projects/(.*?)\"',s).group(1)\n",
    "\n",
    "                url_p = 'https://www.kickstarter.com/projects/'+regex\n",
    "                url_p = re.sub('/description','',url_p)\n",
    "                if url_p.count('/') > 5:\n",
    "                    url_p = '/'.join(url_p.split('/')[:6])\n",
    "\n",
    "                # Scrape each project's page\n",
    "                scrape = scrape_kickstarter_project(url_p)\n",
    "                if scrape:\n",
    "                    scrape.append(url_p)\n",
    "\n",
    "                # Append result of scrape to scrape_df\n",
    "                scrape_df.loc[len(scrape_df)] = scrape\n",
    "    \n",
    "    return scrape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results of web scraping into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ecc8f5852d401a97a724377b9fbc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=609)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fed1598c2444cc3a1cb838f60119be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=276)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scrape_df = browse_kickstarter_results(urls)\n",
    "scrape_df.to_csv('kickstarter_tech_db',sep='\\t',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_df.to_csv('kickstarter_tech_db',sep='\\t',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrame from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>backers</th>\n",
       "      <th>pledged</th>\n",
       "      <th>goal</th>\n",
       "      <th>pct_funded</th>\n",
       "      <th>successful</th>\n",
       "      <th>funding_start_dt</th>\n",
       "      <th>funding_end_dt</th>\n",
       "      <th>live</th>\n",
       "      <th>location</th>\n",
       "      <th>category</th>\n",
       "      <th>tag</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fluent Forever, The App: Learn to *Think* in A...</td>\n",
       "      <td>4434.0</td>\n",
       "      <td>587785.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2.351140</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-09-19 00:00:00</td>\n",
       "      <td>2017-10-19 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Project We Love</td>\n",
       "      <td>Why learn to translate, when you can build flu...</td>\n",
       "      <td>Why learn to translate, when you can learn tot...</td>\n",
       "      <td>https://www.kickstarter.com/projects/gabrielwy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flag・free photo prints - forever!</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>331949.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>33.194900</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-09-14 00:00:00</td>\n",
       "      <td>2016-10-28 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Venice, Los Angeles, CA</td>\n",
       "      <td>Apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An app that delivers 20 free photo prints a mo...</td>\n",
       "      <td>Flag is currently available for iOS, you cando...</td>\n",
       "      <td>https://www.kickstarter.com/projects/flag/flag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devslopes - ANYONE Can Learn to Code</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>192056.0</td>\n",
       "      <td>39500.0</td>\n",
       "      <td>4.862177</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-04-19 00:00:00</td>\n",
       "      <td>2016-05-19 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Orem, UT</td>\n",
       "      <td>Apps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Devslopes is the world's most effective and af...</td>\n",
       "      <td>Devslopes Game Development AcademyLater this y...</td>\n",
       "      <td>https://www.kickstarter.com/projects/912791163...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             project  backers   pledged  \\\n",
       "0  Fluent Forever, The App: Learn to *Think* in A...   4434.0  587785.0   \n",
       "1                  Flag・free photo prints - forever!   5120.0  331949.0   \n",
       "2               Devslopes - ANYONE Can Learn to Code   2149.0  192056.0   \n",
       "\n",
       "       goal  pct_funded successful     funding_start_dt       funding_end_dt  \\\n",
       "0  250000.0    2.351140       True  2017-09-19 00:00:00  2017-10-19 00:00:00   \n",
       "1   10000.0   33.194900       True  2016-09-14 00:00:00  2016-10-28 00:00:00   \n",
       "2   39500.0    4.862177       True  2016-04-19 00:00:00  2016-05-19 00:00:00   \n",
       "\n",
       "    live                 location category              tag  \\\n",
       "0  False              Chicago, IL     Apps  Project We Love   \n",
       "1  False  Venice, Los Angeles, CA     Apps              NaN   \n",
       "2  False                 Orem, UT     Apps              NaN   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Why learn to translate, when you can build flu...   \n",
       "1  An app that delivers 20 free photo prints a mo...   \n",
       "2  Devslopes is the world's most effective and af...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Why learn to translate, when you can learn tot...   \n",
       "1  Flag is currently available for iOS, you cando...   \n",
       "2  Devslopes Game Development AcademyLater this y...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.kickstarter.com/projects/gabrielwy...  \n",
       "1  https://www.kickstarter.com/projects/flag/flag...  \n",
       "2  https://www.kickstarter.com/projects/912791163...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kickstarter_tech_db',sep='\\t')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['funding_start_dt'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date strings to datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['funding_start_dt'] = df['funding_start_dt'].apply(lambda x: \n",
    "                                                      datetime.strptime(x[:10],'%Y-%m-%d'))\n",
    "df['funding_end_dt'] = df['funding_end_dt'].apply(lambda x: \n",
    "                                                  datetime.strptime(x[:10],'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix 'live' mistake in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['live'] = df['funding_end_dt'].apply(lambda x: False if x < datetime(2018,11,9) else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['live'] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NaN values to False in 'successful' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['successful'] = df['successful'].apply(lambda x: False if x is Nan else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
